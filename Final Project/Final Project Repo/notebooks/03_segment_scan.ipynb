{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e9aeb9",
   "metadata": {},
   "source": [
    "# PROMPT_1D_SCAN — SEGMENTATION & EFFECT SIZE\n",
    "\n",
    "High-priority hypotheses (from `docs/hypotheses.md`):\n",
    "- **H1**: `ffpi_food` level and MoM % = `(ffpi_food / ffpi_food.shift(1) - 1) * 100` — Regime means: 2018–2019 vs 2020–2022 vs 2023–2025.\n",
    "- **H2**: `ffpi_veg_oils` vs `ffpi_food` levels (corr/β) — Overall and by regime.\n",
    "- **H4**: Lead–lag: `bdi_price` (lead 1–2 months) vs `ffpi_food` MoM % — Pre-COVID vs 2020–2022 vs 2023–2025.\n",
    "- **H5**: Import pass-through: corr/β of `ipi_food` level vs `ffpi_food` level — Overall and by regime.\n",
    "- **H6**: Local demand dampening: `rs_dairy_products` and `rs_fresh` vs `ffpi_food` (corr, slopes) — Compare high-FFPI months vs others.\n",
    "\n",
    "The cells below load the cleaned panel (`data/clean/data_clean.parquet`), derive KPIs, compute segment summaries/comparisons, and export CSVs (`data/derived/segment_summary.csv`, `data/derived/segment_scoreboard.csv`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db030c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "\n",
    "# Resolve cleaned dataset paths for both notebook and repo-root execution\n",
    "path_candidates = [\n",
    "    (Path('data/clean/data_clean.parquet'), Path('data/cleaned.csv')),\n",
    "    (Path('..') / 'data' / 'clean' / 'data_clean.parquet', Path('..') / 'data' / 'cleaned.csv'),\n",
    "    (Path('Final Project/Final Project Repo/data/clean/data_clean.parquet'), Path('Final Project/Final Project Repo/data/cleaned.csv')),\n",
    "]\n",
    "selected = next(((p, f) for p, f in path_candidates if p.exists() or f.exists()), None)\n",
    "if selected is None:\n",
    "    raise FileNotFoundError('No cleaned dataset found under data/clean/ or data/.')\n",
    "DATA_PATH, FALLBACK_CSV = selected\n",
    "DERIVED_DIR = Path('data/derived') if Path('data').exists() else Path('..') / 'data' / 'derived'\n",
    "DERIVED_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_panel(path: Path, fallback: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load the cleaned panel, preferring Parquet but falling back to CSV for local testing.\"\"\"\n",
    "    if path.exists():\n",
    "        df = pd.read_parquet(path)\n",
    "    elif fallback.exists():\n",
    "        df = pd.read_csv(fallback)\n",
    "    else:\n",
    "        raise FileNotFoundError(f'No cleaned dataset found at {path} or {fallback}.')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def add_derived_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create KPIs and segmentation helpers used in the high-priority hypotheses.\"\"\"\n",
    "    enriched = df.copy()\n",
    "    enriched['ffpi_food_mom_pct'] = enriched['ffpi_food'].pct_change() * 100\n",
    "    enriched['ffpi_food_yoy_pct'] = enriched['ffpi_food'].pct_change(12) * 100\n",
    "    enriched['bdi_price_lead1'] = enriched['bdi_price'].shift(-1)\n",
    "    enriched['bdi_price_lead2'] = enriched['bdi_price'].shift(-2)\n",
    "\n",
    "    # Regime buckets for pre-/during-/post-stress comparisons.\n",
    "    enriched['regime'] = pd.cut(\n",
    "        enriched['date'].dt.year,\n",
    "        bins=[2017, 2019, 2022, 2025],\n",
    "        labels=['2018-2019', '2020-2022', '2023-2025']\n",
    "    )\n",
    "    enriched['high_ffpi_flag'] = enriched['ffpi_food'] >= enriched['ffpi_food'].quantile(0.75)\n",
    "    return enriched\n",
    "\n",
    "def correlation_metric(data: pd.DataFrame, x: str, y: str) -> Tuple[float, int]:\n",
    "    \"\"\"Compute a Pearson correlation and return the value with the usable sample size.\"\"\"\n",
    "    aligned = data[[x, y]].dropna()\n",
    "    if len(aligned) < 2:\n",
    "        return np.nan, len(aligned)\n",
    "    return aligned[x].corr(aligned[y]), len(aligned)\n",
    "\n",
    "def welch_t_pvalue(a: pd.Series, b: pd.Series) -> float:\n",
    "    \"\"\"Welch's t-test p-value for unequal variances; returns NaN if not enough data.\"\"\"\n",
    "    a_clean, b_clean = a.dropna(), b.dropna()\n",
    "    if len(a_clean) < 2 or len(b_clean) < 2:\n",
    "        return np.nan\n",
    "    test = stats.ttest_ind(a_clean, b_clean, equal_var=False)\n",
    "    return test.pvalue\n",
    "\n",
    "def summarize_metric(df: pd.DataFrame, metric: Dict[str, Any], segment_col: str) -> pd.DataFrame:\n",
    "    \"\"\"Summaries (mean/median/N) for a KPI across segment values plus overall.\"\"\"\n",
    "    rows = []\n",
    "    segment_values = list(df[segment_col].dropna().unique())\n",
    "    for segment_value in segment_values + ['Overall']:\n",
    "        segment_df = df if segment_value == 'Overall' else df[df[segment_col] == segment_value]\n",
    "        if metric['type'] == 'series':\n",
    "            series = segment_df[metric['kpi']].dropna()\n",
    "            rows.append({\n",
    "                'KPI_name': metric['label'],\n",
    "                'segment_dimension': segment_col,\n",
    "                'segment_value': segment_value,\n",
    "                'mean': series.mean(),\n",
    "                'median': series.median(),\n",
    "                'N': len(series)\n",
    "            })\n",
    "        elif metric['type'] == 'correlation':\n",
    "            corr_value, sample_size = correlation_metric(segment_df, metric['x'], metric['y'])\n",
    "            rows.append({\n",
    "                'KPI_name': metric['label'],\n",
    "                'segment_dimension': segment_col,\n",
    "                'segment_value': segment_value,\n",
    "                'mean': corr_value,\n",
    "                'median': corr_value,\n",
    "                'N': sample_size\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def compare_segments(df: pd.DataFrame, metric: Dict[str, Any], segment_col: str, pairs: List[Tuple[Any, Any]], min_n: int = 8) -> pd.DataFrame:\n",
    "    \"\"\"Compute differences/ratios (and optional p-values) between segment pairs.\"\"\"\n",
    "    rows = []\n",
    "    for seg_a, seg_b in pairs:\n",
    "        df_a = df if seg_a == 'Overall' else df[df[segment_col] == seg_a]\n",
    "        df_b = df if seg_b == 'Overall' else df[df[segment_col] == seg_b]\n",
    "        if metric['type'] == 'series':\n",
    "            series_a, series_b = df_a[metric['kpi']].dropna(), df_b[metric['kpi']].dropna()\n",
    "            mean_a, mean_b = series_a.mean(), series_b.mean()\n",
    "            diff = mean_a - mean_b\n",
    "            ratio = (mean_a / mean_b) if pd.notnull(mean_a) and pd.notnull(mean_b) and mean_b != 0 else np.nan\n",
    "            p_value = welch_t_pvalue(series_a, series_b) if (len(series_a) >= min_n and len(series_b) >= min_n) else np.nan\n",
    "            rows.append({\n",
    "                'KPI': metric['label'],\n",
    "                'segment_dimension': segment_col,\n",
    "                'segment_A': seg_a,\n",
    "                'segment_B': seg_b,\n",
    "                'diff': diff,\n",
    "                'ratio': ratio,\n",
    "                'N_A': len(series_a),\n",
    "                'N_B': len(series_b),\n",
    "                'p_value': p_value\n",
    "            })\n",
    "        elif metric['type'] == 'correlation':\n",
    "            corr_a, n_a = correlation_metric(df_a, metric['x'], metric['y'])\n",
    "            corr_b, n_b = correlation_metric(df_b, metric['x'], metric['y'])\n",
    "            diff = corr_a - corr_b if pd.notnull(corr_a) and pd.notnull(corr_b) else np.nan\n",
    "            ratio = (corr_a / corr_b) if pd.notnull(corr_a) and pd.notnull(corr_b) and corr_b != 0 else np.nan\n",
    "            rows.append({\n",
    "                'KPI': metric['label'],\n",
    "                'segment_dimension': segment_col,\n",
    "                'segment_A': seg_a,\n",
    "                'segment_B': seg_b,\n",
    "                'diff': diff,\n",
    "                'ratio': ratio,\n",
    "                'N_A': n_a,\n",
    "                'N_B': n_b,\n",
    "                'p_value': np.nan\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def build_scoreboard(comparisons: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"Rank segment differences by absolute effect size, ratio distance, and sample size.\"\"\"\n",
    "    scoreboard = pd.concat(comparisons, ignore_index=True)\n",
    "    scoreboard['abs_diff'] = scoreboard['diff'].abs()\n",
    "    scoreboard['ratio_deviation'] = scoreboard['ratio'].apply(lambda r: abs(r - 1) if pd.notnull(r) else np.nan)\n",
    "    scoreboard['n_min'] = scoreboard[['N_A', 'N_B']].min(axis=1)\n",
    "    scoreboard = scoreboard.sort_values(['abs_diff', 'ratio_deviation', 'n_min'], ascending=[False, False, False])\n",
    "    return scoreboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis-specific KPI configurations\n",
    "regime_pairs = [('2018-2019', '2020-2022'), ('2020-2022', '2023-2025'), ('2018-2019', '2023-2025')]\n",
    "high_ffpi_pairs = [(True, False)]\n",
    "\n",
    "hypothesis_plan = [\n",
    "    {\n",
    "        'id': 'H1',\n",
    "        'description': 'ffpi_food level and MoM% by regime',\n",
    "        'segment': 'regime',\n",
    "        'pairs': regime_pairs,\n",
    "        'metrics': [\n",
    "            {'type': 'series', 'kpi': 'ffpi_food', 'label': 'FFPI Food level'},\n",
    "            {'type': 'series', 'kpi': 'ffpi_food_mom_pct', 'label': 'FFPI Food MoM %'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'id': 'H2',\n",
    "        'description': 'Veg oils vs food (levels + correlation)',\n",
    "            'segment': 'regime',\n",
    "        'pairs': regime_pairs,\n",
    "        'metrics': [\n",
    "            {'type': 'series', 'kpi': 'ffpi_veg_oils', 'label': 'Veg oils level'},\n",
    "            {'type': 'series', 'kpi': 'ffpi_food', 'label': 'FFPI Food level'},\n",
    "            {'type': 'series', 'kpi': 'veg_food_ratio', 'label': 'Veg/food level ratio'},\n",
    "            {'type': 'correlation', 'x': 'ffpi_veg_oils', 'y': 'ffpi_food', 'label': 'Corr(veg oils, food)'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'id': 'H4',\n",
    "        'description': 'BDI lead (1–2m) vs FFPI MoM%',\n",
    "        'segment': 'regime',\n",
    "        'pairs': regime_pairs,\n",
    "        'metrics': [\n",
    "            {'type': 'correlation', 'x': 'bdi_price_lead1', 'y': 'ffpi_food_mom_pct', 'label': 'Corr(BDI lead1, FFPI MoM%)'},\n",
    "            {'type': 'correlation', 'x': 'bdi_price_lead2', 'y': 'ffpi_food_mom_pct', 'label': 'Corr(BDI lead2, FFPI MoM%)'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'id': 'H5',\n",
    "        'description': 'Import pass-through: IPI food vs FFPI food',\n",
    "        'segment': 'regime',\n",
    "        'pairs': regime_pairs,\n",
    "        'metrics': [\n",
    "            {'type': 'series', 'kpi': 'ipi_food', 'label': 'IPI food level'},\n",
    "            {'type': 'correlation', 'x': 'ipi_food', 'y': 'ffpi_food', 'label': 'Corr(IPI food, FFPI food)'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'id': 'H6',\n",
    "        'description': 'Retail demand dampening vs FFPI food',\n",
    "        'segment': 'high_ffpi_flag',\n",
    "        'pairs': high_ffpi_pairs,\n",
    "        'metrics': [\n",
    "            {'type': 'correlation', 'x': 'rs_dairy_products', 'y': 'ffpi_food', 'label': 'Corr(RS dairy, FFPI food)'},\n",
    "            {'type': 'correlation', 'x': 'rs_fresh', 'y': 'ffpi_food', 'label': 'Corr(RS fresh, FFPI food)'}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Derived ratios added here to keep transforms centralized\n",
    "def attach_transforms(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['veg_food_ratio'] = df['ffpi_veg_oils'] / df['ffpi_food']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775fbed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the scan\n",
    "panel = add_derived_features(load_panel(DATA_PATH, FALLBACK_CSV))\n",
    "panel = attach_transforms(panel)\n",
    "\n",
    "segment_summaries: List[pd.DataFrame] = []\n",
    "segment_comparisons: List[pd.DataFrame] = []\n",
    "\n",
    "for hypothesis in hypothesis_plan:\n",
    "    segment = hypothesis['segment']\n",
    "    pairs = hypothesis['pairs']\n",
    "    for metric in hypothesis['metrics']:\n",
    "        summary = summarize_metric(panel, metric, segment)\n",
    "        summary['hypothesis'] = hypothesis['id']\n",
    "        segment_summaries.append(summary)\n",
    "        comparisons = compare_segments(panel, metric, segment, pairs)\n",
    "        comparisons['hypothesis'] = hypothesis['id']\n",
    "        segment_comparisons.append(comparisons)\n",
    "\n",
    "segment_summary_df = pd.concat(segment_summaries, ignore_index=True)\n",
    "comparison_df = pd.concat(segment_comparisons, ignore_index=True)\n",
    "scoreboard_df = build_scoreboard(segment_comparisons)\n",
    "\n",
    "segment_summary_path = DERIVED_DIR / 'segment_summary.csv'\n",
    "scoreboard_path = DERIVED_DIR / 'segment_scoreboard.csv'\n",
    "segment_summary_df.to_csv(segment_summary_path, index=False)\n",
    "scoreboard_df.to_csv(scoreboard_path, index=False)\n",
    "\n",
    "segment_summary_df.head(), comparison_df.head(), scoreboard_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
