{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e9aeb9",
   "metadata": {},
   "source": [
    "# PROMPT_1D_SCAN — SEGMENTATION & EFFECT SIZE\n",
    "\n",
    "High-priority hypotheses (from `docs/hypotheses.md`):\n",
    "- **H1**: `ffpi_food` level and MoM % = `(ffpi_food / ffpi_food.shift(1) - 1) * 100` — Regime means: 2018–2019 vs 2020–2022 vs 2023–2025.\n",
    "- **H2**: `ffpi_veg_oils` vs `ffpi_food` levels (corr/β) — Overall and by regime.\n",
    "- **H4**: Lead–lag: `bdi_price` (lead 1–2 months) vs `ffpi_food` MoM % — Pre-COVID vs 2020–2022 vs 2023–2025.\n",
    "- **H5**: Import pass-through: corr/β of `ipi_food` level vs `ffpi_food` level — Overall and by regime.\n",
    "- **H6**: Local demand dampening: `rs_dairy_products` and `rs_fresh` vs `ffpi_food` (corr, slopes) — Compare high-FFPI months vs others.\n",
    "\n",
    "The cells below load the cleaned panel (`data/clean/data_clean.parquet`), derive KPIs, compute segment summaries/comparisons, and export CSVs (`data/derived/segment_summary.csv`, `data/derived/segment_scoreboard.csv`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db030c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "\n",
    "# Resolve cleaned dataset paths for both notebook and repo-root execution\n",
    "path_candidates = [\n",
    "    (Path('data/clean/data_clean.parquet'), Path('data/cleaned.csv')),\n",
    "    (Path('..') / 'data' / 'clean' / 'data_clean.parquet', Path('..') / 'data' / 'cleaned.csv'),\n",
    "    (Path('Final Project/Final Project Repo/data/clean/data_clean.parquet'), Path('Final Project/Final Project Repo/data/cleaned.csv')),\n",
    "]\n",
    "selected = next(((p, f) for p, f in path_candidates if p.exists() or f.exists()), None)\n",
    "if selected is None:\n",
    "    raise FileNotFoundError('No cleaned dataset found under data/clean/ or data/.')\n",
    "DATA_PATH, FALLBACK_CSV = selected\n",
    "DERIVED_DIR = Path('data/derived') if Path('data').exists() else Path('..') / 'data' / 'derived'\n",
    "DERIVED_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92d4947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_panel(path: Path, fallback: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load the cleaned panel, defaulting to CSV to avoid parquet engine issues.\"\"\"\n",
    "    if fallback.exists():\n",
    "        df = pd.read_csv(fallback)\n",
    "    elif path.exists():\n",
    "        try:\n",
    "            import pyarrow  # noqa: F401\n",
    "            df = pd.read_parquet(path)\n",
    "        except Exception as exc:\n",
    "            raise RuntimeError(\n",
    "                f\"Failed to read parquet at {path}; no CSV fallback found.\"\n",
    "            ) from exc\n",
    "    else:\n",
    "        raise FileNotFoundError(f'No cleaned dataset found at {path} or {fallback}.')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa49eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis-specific KPI configurations\n",
    "regime_pairs = [('2018-2019', '2020-2022'), ('2020-2022', '2023-2025'), ('2018-2019', '2023-2025')]\n",
    "high_ffpi_pairs = [(True, False)]\n",
    "\n",
    "hypothesis_plan = [\n",
    "    {\n",
    "        'id': 'H1',\n",
    "        'description': 'ffpi_food level and MoM% by regime',\n",
    "        'segment': 'regime',\n",
    "        'pairs': regime_pairs,\n",
    "        'metrics': [\n",
    "            {'type': 'series', 'kpi': 'ffpi_food', 'label': 'FFPI Food level'},\n",
    "            {'type': 'series', 'kpi': 'ffpi_food_mom_pct', 'label': 'FFPI Food MoM %'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'id': 'H2',\n",
    "        'description': 'Veg oils vs food (levels + correlation)',\n",
    "            'segment': 'regime',\n",
    "        'pairs': regime_pairs,\n",
    "        'metrics': [\n",
    "            {'type': 'series', 'kpi': 'ffpi_veg_oils', 'label': 'Veg oils level'},\n",
    "            {'type': 'series', 'kpi': 'ffpi_food', 'label': 'FFPI Food level'},\n",
    "            {'type': 'series', 'kpi': 'veg_food_ratio', 'label': 'Veg/food level ratio'},\n",
    "            {'type': 'correlation', 'x': 'ffpi_veg_oils', 'y': 'ffpi_food', 'label': 'Corr(veg oils, food)'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'id': 'H4',\n",
    "        'description': 'BDI lead (1–2m) vs FFPI MoM%',\n",
    "        'segment': 'regime',\n",
    "        'pairs': regime_pairs,\n",
    "        'metrics': [\n",
    "            {'type': 'correlation', 'x': 'bdi_price_lead1', 'y': 'ffpi_food_mom_pct', 'label': 'Corr(BDI lead1, FFPI MoM%)'},\n",
    "            {'type': 'correlation', 'x': 'bdi_price_lead2', 'y': 'ffpi_food_mom_pct', 'label': 'Corr(BDI lead2, FFPI MoM%)'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'id': 'H5',\n",
    "        'description': 'Import pass-through: IPI food vs FFPI food',\n",
    "        'segment': 'regime',\n",
    "        'pairs': regime_pairs,\n",
    "        'metrics': [\n",
    "            {'type': 'series', 'kpi': 'ipi_food', 'label': 'IPI food level'},\n",
    "            {'type': 'correlation', 'x': 'ipi_food', 'y': 'ffpi_food', 'label': 'Corr(IPI food, FFPI food)'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'id': 'H6',\n",
    "        'description': 'Retail demand dampening vs FFPI food',\n",
    "        'segment': 'high_ffpi_flag',\n",
    "        'pairs': high_ffpi_pairs,\n",
    "        'metrics': [\n",
    "            {'type': 'correlation', 'x': 'rs_dairy_products', 'y': 'ffpi_food', 'label': 'Corr(RS dairy, FFPI food)'},\n",
    "            {'type': 'correlation', 'x': 'rs_fresh', 'y': 'ffpi_food', 'label': 'Corr(RS fresh, FFPI food)'}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Derived ratios added here to keep transforms centralized\n",
    "def attach_transforms(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['veg_food_ratio'] = df['ffpi_veg_oils'] / df['ffpi_food']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "775fbed9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowKeyError",
     "evalue": "A type extension with name pandas.period already defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArrowKeyError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Execute the scan\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m panel = add_derived_features(\u001b[43mload_panel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFALLBACK_CSV\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      3\u001b[39m panel = attach_transforms(panel)\n\u001b[32m      5\u001b[39m segment_summaries: List[pd.DataFrame] = []\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mload_panel\u001b[39m\u001b[34m(path, fallback)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fallback.exists():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\OneDrive\\Documentos\\GitHub\\exchange-stadistics\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:653\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;129m@doc\u001b[39m(storage_options=_shared_docs[\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_parquet\u001b[39m(\n\u001b[32m    502\u001b[39m     path: FilePath | ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    510\u001b[39m     **kwargs,\n\u001b[32m    511\u001b[39m ) -> DataFrame:\n\u001b[32m    512\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    513\u001b[39m \u001b[33;03m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[32m    514\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    650\u001b[39m \u001b[33;03m    1    4    9\u001b[39;00m\n\u001b[32m    651\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     impl = \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_nullable_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default:\n\u001b[32m    656\u001b[39m         msg = (\n\u001b[32m    657\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe argument \u001b[39m\u001b[33m'\u001b[39m\u001b[33muse_nullable_dtypes\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will be removed \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    658\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33min a future version.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    659\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\OneDrive\\Documentos\\GitHub\\exchange-stadistics\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:64\u001b[39m, in \u001b[36mget_engine\u001b[39m\u001b[34m(engine)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m engine_class \u001b[38;5;129;01min\u001b[39;00m engine_classes:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     66\u001b[39m         error_msgs += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m - \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(err)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\OneDrive\\Documentos\\GitHub\\exchange-stadistics\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:170\u001b[39m, in \u001b[36mPyArrowImpl.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# import utils to register the pyarrow extension types\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension_types\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[38;5;28mself\u001b[39m.api = pyarrow\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\OneDrive\\Documentos\\GitHub\\exchange-stadistics\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\extension_types.py:59\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# register the type with a dummy instance\u001b[39;00m\n\u001b[32m     58\u001b[39m _period_type = ArrowPeriodType(\u001b[33m\"\u001b[39m\u001b[33mD\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43mpyarrow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister_extension_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_period_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mArrowIntervalType\u001b[39;00m(pyarrow.ExtensionType):\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, subtype, closed: IntervalClosedType) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     64\u001b[39m         \u001b[38;5;66;03m# attributes need to be set first before calling\u001b[39;00m\n\u001b[32m     65\u001b[39m         \u001b[38;5;66;03m# super init (as that calls serialize)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\OneDrive\\Documentos\\GitHub\\exchange-stadistics\\.venv\\Lib\\site-packages\\pyarrow\\types.pxi:2226\u001b[39m, in \u001b[36mpyarrow.lib.register_extension_type\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\OneDrive\\Documentos\\GitHub\\exchange-stadistics\\.venv\\Lib\\site-packages\\pyarrow\\error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mArrowKeyError\u001b[39m: A type extension with name pandas.period already defined"
     ]
    }
   ],
   "source": [
    "# Execute the scan\n",
    "panel = add_derived_features(load_panel(DATA_PATH, FALLBACK_CSV))\n",
    "panel = attach_transforms(panel)\n",
    "\n",
    "segment_summaries: List[pd.DataFrame] = []\n",
    "segment_comparisons: List[pd.DataFrame] = []\n",
    "\n",
    "for hypothesis in hypothesis_plan:\n",
    "    segment = hypothesis['segment']\n",
    "    pairs = hypothesis['pairs']\n",
    "    for metric in hypothesis['metrics']:\n",
    "        summary = summarize_metric(panel, metric, segment)\n",
    "        summary['hypothesis'] = hypothesis['id']\n",
    "        segment_summaries.append(summary)\n",
    "        comparisons = compare_segments(panel, metric, segment, pairs)\n",
    "        comparisons['hypothesis'] = hypothesis['id']\n",
    "        segment_comparisons.append(comparisons)\n",
    "\n",
    "segment_summary_df = pd.concat(segment_summaries, ignore_index=True)\n",
    "comparison_df = pd.concat(segment_comparisons, ignore_index=True)\n",
    "scoreboard_df = build_scoreboard(segment_comparisons)\n",
    "\n",
    "segment_summary_path = DERIVED_DIR / 'segment_summary.csv'\n",
    "scoreboard_path = DERIVED_DIR / 'segment_scoreboard.csv'\n",
    "segment_summary_df.to_csv(segment_summary_path, index=False)\n",
    "scoreboard_df.to_csv(scoreboard_path, index=False)\n",
    "\n",
    "segment_summary_df.head(), comparison_df.head(), scoreboard_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
